# backend/app/workers/scheduler_worker.py
"""
Refactored Scheduler Worker for Timelapser v4.

ARCHITECTURE RELATIONSHIPS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

This is the MAIN COORDINATOR that orchestrates all scheduler operations:

â”Œâ”€ CORE SCHEDULER (this file) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ APScheduler lifecycle management                                                   â”‚
â”‚ â€¢ Job registry and coordination                                                      â”‚
â”‚ â€¢ Timelapse capture job scheduling                                                   â”‚
â”‚ â€¢ Integration point for all specialized managers                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚                 â”‚                 â”‚
                          â–¼                 â–¼                 â–¼

â”Œâ”€ UTILITIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€ JOB MANAGERS â”€â”  â”Œâ”€ EVALUATORS â”€â”€â”
â”‚ â€¢ SchedulerTimeUtilsâ”‚  â”‚ â€¢ ImmediateJobM.â”‚  â”‚ â€¢ AutomationE. â”‚
â”‚ â€¢ JobIdGenerator    â”‚  â”‚ â€¢ StandardJobM. â”‚  â”‚               â”‚
â”‚ â€¢ SchedulerJobTempl.â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DEPENDENCIES FLOW:
1. SchedulerWorker creates and coordinates all managers
2. Managers use shared utilities (SchedulerTimeUtils, JobIdGenerator)
3. All components use the same database and job registry references
4. Function references are injected from SchedulerWorker into managers

REFACTORING IMPACT:
â€¢ Original: 1,544 lines with massive duplication
â€¢ Refactored: 427 lines with proper separation of concerns
â€¢ 83% size reduction while maintaining full functionality
"""
from typing import Dict, Any, Callable, Optional, List
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.job import Job

from .base_worker import BaseWorker
from .utils.worker_status_builder import WorkerStatusBuilder
from ..services.logger import get_service_logger
from ..enums import LoggerName, LogSource, WorkerType, LogEmoji
from ..services.scheduler_workflow_service import SchedulerWorkflowService
from .utils import SchedulerTimeUtils, JobIdGenerator, SchedulerJobTemplate
from .immediate_job_manager import ImmediateJobManager
from .standard_job_manager import StandardJobManager
from .automation_evaluator import AutomationEvaluator
from ..services.settings_service import SyncSettingsService
from ..services.scheduling.capture_timing_service import SyncCaptureTimingService
from ..database.timelapse_operations import SyncTimelapseOperations
from ..database.sse_events_operations import SyncSSEEventsOperations
from ..database.scheduled_job_operations import SyncScheduledJobOperations
from ..database.core import SyncDatabase
from ..models.scheduled_job_model import ScheduledJobCreate
from ..utils.time_utils import utc_now
from ..constants import (
    SCHEDULER_MAX_INSTANCES,
)
from ..enums import JobPriority

# Initialize scheduler worker logger
scheduler_logger = get_service_logger(LoggerName.SCHEDULER_WORKER, LogSource.WORKER)


class SchedulerWorker(BaseWorker):
    """
    Refactored scheduler worker with proper separation of concerns.

    Responsibilities:
    - APScheduler lifecycle management
    - Timelapse capture job scheduling
    - Coordination of specialized managers
    """

    def __init__(
        self,
        settings_service: SyncSettingsService,
        db: SyncDatabase,
        scheduling_service: SyncCaptureTimingService,
    ):
        """
        Initialize scheduler worker with injected dependencies.

        Args:
            settings_service: Settings operations service
            db: Sync database instance for timelapse operations
            scheduling_service: Scheduling service for capture validation (required)
        """
        super().__init__(WorkerType.SCHEDULER_WORKER)

        # Core dependencies
        self.settings_service = settings_service
        self.db = db
        self.scheduling_service = scheduling_service

        # Database operations
        self.timelapse_ops = SyncTimelapseOperations(db)
        self.sse_ops = SyncSSEEventsOperations(db)
        self.scheduled_job_ops = SyncScheduledJobOperations(db)

        # APScheduler setup
        self.scheduler = AsyncIOScheduler()
        self.job_registry: Dict[str, Job] = {}

        # External function references
        self.timelapse_capture_func: Optional[Callable] = None

        # Initialize workflow service for Service Layer Boundary Pattern
        self.scheduler_service = SchedulerWorkflowService()

        # Utility and manager initialization
        self._initialize_managers()

    def _initialize_managers(self) -> None:
        """Initialize specialized managers and utilities."""
        # Time utilities with caching
        self.time_utils = SchedulerTimeUtils(self.settings_service)

        # Job template for common patterns
        self.job_template = SchedulerJobTemplate(
            self.scheduler, self.job_registry, self.time_utils
        )

        # Immediate job manager
        self.immediate_job_manager = ImmediateJobManager(
            self.scheduler,
            self.job_registry,
            self.db,
            self.time_utils,
            WorkerType.SCHEDULER_WORKER,
        )

        # Standard job manager
        self.standard_job_manager = StandardJobManager(
            self.scheduler,
            self.job_registry,
            self.db,
            self.time_utils,
            WorkerType.SCHEDULER_WORKER,
        )

        # Automation evaluator
        self.automation_evaluator = AutomationEvaluator(
            self.db, self.time_utils, WorkerType.SCHEDULER_WORKER
        )

        # Inject function references
        self._inject_function_references()

    def _inject_function_references(self) -> None:
        """Inject function references into managers."""
        # Inject into immediate job manager
        self.immediate_job_manager.timelapse_capture_func = (
            self._get_timelapse_capture_func
        )

        # Inject into automation evaluator
        self.automation_evaluator.schedule_immediate_video_func = (
            self.schedule_immediate_video_generation
        )

    def _get_timelapse_capture_func(self) -> Optional[Callable]:
        """Get the timelapse capture function reference."""
        return self.timelapse_capture_func

    async def initialize(self) -> None:
        """Initialize scheduler worker resources and rebuild jobs from database."""
        scheduler_logger.info("Initializing refactored per-timelapse scheduler worker", store_in_db=False, emoji=LogEmoji.SYSTEM)

        # Start scheduler first
        self.start_scheduler()

        # Rebuild APScheduler jobs from database
        await self._rebuild_jobs_from_database()

        scheduler_logger.info("Scheduler worker initialization completed", store_in_db=False, emoji=LogEmoji.SUCCESS)

    async def cleanup(self) -> None:
        """Cleanup scheduler worker resources."""
        scheduler_logger.info("Cleaning up refactored scheduler worker", store_in_db=False, emoji=LogEmoji.CLEANUP)

        try:
            if self.scheduler.running:
                self.scheduler.shutdown(wait=False)
                scheduler_logger.info("Scheduler shut down")
        except Exception as e:
            scheduler_logger.error(f"Error shutting down scheduler: {e}", store_in_db=False)

    # APScheduler Management

    def start_scheduler(self) -> None:
        """Start the APScheduler instance."""
        try:
            if not self.scheduler.running:
                self.scheduler.start()
                scheduler_logger.info("Scheduler started successfully", store_in_db=False, emoji=LogEmoji.SUCCESS)
            else:
                scheduler_logger.debug("Scheduler already running", store_in_db=False)
        except Exception as e:
            scheduler_logger.error(f"Failed to start scheduler: {e}", store_in_db=False)
            raise

    def stop_scheduler(self) -> None:
        """Stop the APScheduler instance."""
        try:
            if self.scheduler.running:
                self.scheduler.shutdown(wait=False)
                scheduler_logger.info("Scheduler stopped", store_in_db=False, emoji=LogEmoji.SYSTEM)
            else:
                scheduler_logger.debug("Scheduler already stopped")
        except Exception as e:
            scheduler_logger.error(f"Error stopping scheduler: {e}", store_in_db=False)

    async def _rebuild_jobs_from_database(self) -> None:
        """Rebuild APScheduler jobs from database on startup."""
        try:
            scheduler_logger.info("Rebuilding APScheduler jobs from database...", store_in_db=False, emoji=LogEmoji.SYSTEM)

            # Get all active scheduled jobs from database
            active_jobs = self.scheduled_job_ops.get_active_jobs()

            if not active_jobs:
                scheduler_logger.info("No active scheduled jobs found in database")
                return

            jobs_rebuilt = 0
            skipped_standard_jobs = 0

            for job_record in active_jobs:
                try:
                    # Determine job type and rebuild accordingly
                    if job_record.job_type == "timelapse_capture":
                        if job_record.entity_id and job_record.interval_seconds:
                            success = self.add_timelapse_job(
                                job_record.entity_id, job_record.interval_seconds
                            )
                            if success:
                                jobs_rebuilt += 1
                                scheduler_logger.debug(
                                    f"Rebuilt timelapse job: {job_record.job_id}"
                                )

                    elif job_record.job_type in [
                        "health_check",
                        "weather_refresh",
                        "video_automation",
                        "automation_triggers",
                        "sync_timelapses",
                        "sse_cleanup",
                    ]:
                        # Standard jobs will be rebuilt when add_standard_jobs is called
                        # Keep them in database but don't rebuild here to avoid duplicates
                        skipped_standard_jobs += 1
                        scheduler_logger.debug(
                            f"Skipping rebuild of standard job: {job_record.job_id}"
                        )

                    else:
                        scheduler_logger.warning(
                            f"Unknown job type for rebuild: {job_record.job_type}"
                        )

                except Exception as job_error:
                    scheduler_logger.error(
                        f"Failed to rebuild job {job_record.job_id}: {job_error}"
                    )

            scheduler_logger.info(
                f"Rebuilt {jobs_rebuilt} timelapse jobs from database "
                f"(skipped {skipped_standard_jobs} standard jobs for later)",
                emoji=LogEmoji.SUCCESS
            )

        except Exception as e:
            scheduler_logger.error(f"Failed to rebuild jobs from database: {e}", store_in_db=False)

    def _persist_job_to_database(self, job_id: str, job_type: str, **kwargs) -> None:
        """Persist APScheduler job to database for visibility and recovery."""
        try:
            # Extract job information
            job = self.job_registry.get(job_id)
            if not job:
                return

            # Determine schedule pattern and interval
            schedule_pattern = None
            interval_seconds = None
            entity_id = None
            entity_type = None

            # Parse job ID to extract entity information
            if job_id.startswith("timelapse_capture_"):
                entity_id = int(job_id.replace("timelapse_capture_", ""))
                entity_type = "timelapse"

                # Get interval from trigger
                if hasattr(job.trigger, "interval"):
                    interval_seconds = int(job.trigger.interval.total_seconds())

            elif job_id.startswith("health_check"):
                entity_type = "system"
                schedule_pattern = "interval"

            # Get next run time
            next_run_time = job.next_run_time

            # Create job record
            job_data = ScheduledJobCreate(
                job_id=job_id,
                job_type=job_type,
                schedule_pattern=schedule_pattern,
                interval_seconds=interval_seconds,
                next_run_time=next_run_time,
                entity_id=entity_id,
                entity_type=entity_type,
                config=kwargs,
                status="active",
            )

            # Persist to database
            self.scheduled_job_ops.create_or_update_job(job_data)
            scheduler_logger.debug(f"Persisted job to database: {job_id}")

        except Exception as e:
            scheduler_logger.warning(f"Failed to persist job {job_id} to database: {e}")

    def _remove_job_from_database(self, job_id: str) -> None:
        """Remove job from database when it's removed from APScheduler."""
        try:
            self.scheduled_job_ops.delete_job(job_id)
            scheduler_logger.debug(f"Removed job from database: {job_id}")
        except Exception as e:
            scheduler_logger.warning(
                f"Failed to remove job {job_id} from database: {e}"
            )

    def _sync_job_timing_to_database(self, job_id: str) -> None:
        """Sync APScheduler job timing information to database."""
        try:
            job = self.job_registry.get(job_id)
            if not job:
                return

            # Update next_run_time in database
            next_run_time = job.next_run_time
            if next_run_time:
                self.scheduled_job_ops.update_job_timing(
                    job_id=job_id, next_run_time=next_run_time
                )
                scheduler_logger.debug(f"Synced timing to database for job {job_id}")

        except Exception as e:
            scheduler_logger.warning(
                f"Failed to sync job timing {job_id} to database: {e}"
            )

    def _update_all_job_timings_in_database(self) -> None:
        """Update all APScheduler job timings in database."""
        try:
            updated_count = 0
            for job_id in self.job_registry:
                self._sync_job_timing_to_database(job_id)
                updated_count += 1

            if updated_count > 0:
                scheduler_logger.debug(
                    f"Updated timing information for {updated_count} jobs in database"
                )

        except Exception as e:
            scheduler_logger.warning(f"Failed to update job timings in database: {e}")

    # Job Management

    def add_job(self, job_id: str, func: Callable, trigger: str, **kwargs) -> bool:
        """
        Add a job to the scheduler with standard configuration and database persistence.

        Args:
            job_id: Unique job identifier
            func: Function to execute
            trigger: APScheduler trigger type
            **kwargs: Additional scheduler arguments

        Returns:
            True if job was added successfully
        """
        try:
            # Remove existing job if present
            if job_id in self.job_registry:
                self.remove_job(job_id)

            # Set default values
            kwargs.setdefault("max_instances", SCHEDULER_MAX_INSTANCES)
            kwargs.setdefault("coalesce", True)
            kwargs.setdefault("misfire_grace_time", 30)

            job = self.scheduler.add_job(
                func=func, trigger=trigger, id=job_id, **kwargs
            )

            if job:
                self.job_registry[job_id] = job

                # Persist job to database for visibility and recovery
                job_type = self._determine_job_type(job_id)
                self._persist_job_to_database(job_id, job_type, **kwargs)

                scheduler_logger.debug(f"Added job {job_id}")
                return True

            return False

        except Exception as e:
            scheduler_logger.error(f"Failed to add job {job_id}: {e}", store_in_db=False)
            return False

    def remove_job(self, job_id: str) -> None:
        """Remove job from scheduler, registry, and database."""
        try:
            if job_id in self.job_registry:
                self.scheduler.remove_job(job_id)
                del self.job_registry[job_id]

                # Remove from database
                self._remove_job_from_database(job_id)

                scheduler_logger.debug(f"Removed job {job_id}")
        except Exception as e:
            scheduler_logger.warning(f"Error removing job {job_id}: {e}")

    def _determine_job_type(self, job_id: str) -> str:
        """Determine job type from job ID."""
        if job_id.startswith("timelapse_capture_"):
            return "timelapse_capture"
        elif job_id.startswith("health_check"):
            return "health_check"
        elif job_id.startswith("weather_refresh"):
            return "weather_refresh"
        elif job_id.startswith("video_automation"):
            return "video_automation"
        elif job_id.startswith("sse_cleanup"):
            return "sse_cleanup"
        elif job_id.startswith("automation_triggers"):
            return "automation_triggers"
        elif job_id.startswith("sync_timelapses"):
            return "sync_timelapses"
        else:
            return "unknown"

    def _track_job_execution(
        self, job_id: str, success: bool = True, error_message: Optional[str] = None
    ) -> None:
        """Track job execution results in database."""
        try:
            current_time = utc_now()

            if success:
                # Update last success time
                self.scheduled_job_ops.update_job_timing(
                    job_id=job_id,
                    last_run_time=current_time,
                    last_success_time=current_time,
                )
            else:
                # Update last failure time
                self.scheduled_job_ops.update_job_timing(
                    job_id=job_id,
                    last_run_time=current_time,
                    last_failure_time=current_time,
                    error_message=error_message,
                )

            scheduler_logger.debug(
                f"Tracked execution for job {job_id}: {'success' if success else 'failure'}"
            )

        except Exception as e:
            scheduler_logger.warning(f"Failed to track execution for job {job_id}: {e}")

    def _create_tracked_job_wrapper(
        self, job_id: str, original_func: Callable
    ) -> Callable:
        """Create a wrapper function that tracks job execution."""
        if hasattr(original_func, "__name__"):
            func_name = original_func.__name__
        else:
            func_name = str(original_func)

        async def tracked_wrapper(*args, **kwargs):
            start_time = utc_now()
            try:
                scheduler_logger.debug(
                    f"Starting tracked execution of job {job_id} ({func_name})",
                    store_in_db=False
                )

                # Execute the original function
                result = await original_func(*args, **kwargs)

                # Track successful execution
                self._track_job_execution(job_id, success=True)

                execution_time = (utc_now() - start_time).total_seconds()
                scheduler_logger.debug(
                    f"Job {job_id} completed successfully in {execution_time:.2f}s",
                    store_in_db=False,
                    emoji=LogEmoji.SUCCESS
                )

                return result

            except Exception as e:
                # Track failed execution
                self._track_job_execution(job_id, success=False, error_message=str(e))

                execution_time = (utc_now() - start_time).total_seconds()
                scheduler_logger.error(
                    f"Job {job_id} failed after {execution_time:.2f}s: {e}",
                    store_in_db=False
                )

                # Re-raise the exception
                raise

        # Preserve function metadata
        tracked_wrapper.__name__ = f"tracked_{func_name}"
        return tracked_wrapper

    # Timelapse Job Management

    def add_timelapse_job(self, timelapse_id: int, interval_seconds: int) -> bool:
        """
        Add timelapse capture job to scheduler.

        Args:
            timelapse_id: ID of timelapse to schedule
            interval_seconds: Capture interval in seconds

        Returns:
            True if job was added successfully
        """
        try:
            if not self.timelapse_capture_func:
                scheduler_logger.error("No timelapse capture function configured")
                return False

            job_id = JobIdGenerator.timelapse_capture(timelapse_id)

            # Create capture wrapper with validation
            async def capture_wrapper():
                scheduler_logger.info(
                    f"Capture wrapper called for timelapse {timelapse_id}",
                    store_in_db=False,
                    emoji=LogEmoji.CAMERA
                )
                try:
                    # Validate capture readiness
                    validation_result = self.scheduling_service.validate_capture_readiness(
                        camera_id=0,  # Will be extracted from timelapse in validation
                        timelapse_id=timelapse_id,
                    )

                    if not validation_result.valid:
                        scheduler_logger.info(
                            f"âŒ Capture blocked for timelapse {timelapse_id}: "
                            f"{validation_result.error or 'Unknown reason'}"
                        )
                        return

                    # Execute capture
                    if self.timelapse_capture_func is not None:
                        scheduler_logger.info(
                            f"ðŸš€ Executing capture for timelapse {timelapse_id}"
                        )
                        await self.timelapse_capture_func(timelapse_id)
                    else:
                        scheduler_logger.error(
                            f"Timelapse capture function not configured for timelapse {timelapse_id}"
                        )

                except Exception as e:
                    scheduler_logger.error(
                        f"Error in capture job for timelapse {timelapse_id}: {e}",
                        store_in_db=False,
                    )

            # Create tracked wrapper for execution monitoring
            tracked_capture_wrapper = self._create_tracked_job_wrapper(
                job_id, capture_wrapper
            )

            # Add the job
            success = self.add_job(
                job_id=job_id,
                func=tracked_capture_wrapper,
                trigger="interval",
                seconds=interval_seconds,
            )

            if success:
                scheduler_logger.info(
                    f"Added timelapse job for timelapse {timelapse_id} (interval: {interval_seconds}s)"
                )
            else:
                scheduler_logger.error(
                    f"Failed to add timelapse job for timelapse {timelapse_id}"
                )

            return success

        except Exception as e:
            scheduler_logger.error(
                f"Error adding timelapse job for {timelapse_id}: {e}", store_in_db=False
            )
            return False

    def remove_timelapse_job(self, timelapse_id: int) -> None:
        """Remove timelapse capture job."""
        job_id = JobIdGenerator.timelapse_capture(timelapse_id)
        self.remove_job(job_id)
        scheduler_logger.info(f"Removed timelapse job for timelapse {timelapse_id}")

    # Standard Jobs Management

    def add_standard_jobs(
        self,
        health_check_func: Optional[Callable] = None,
        weather_refresh_func: Optional[Callable] = None,
        video_automation_func: Optional[Callable] = None,
        sse_cleanup_func: Optional[Callable] = None,
    ) -> int:
        """
        Add all standard recurring jobs with execution tracking.

        Args:
            health_check_func: Health monitoring function
            weather_refresh_func: Weather data refresh function
            video_automation_func: Video automation processing function
            sse_cleanup_func: SSE cleanup function

        Returns:
            Number of jobs successfully added
        """
        # Create tracked wrappers for all standard functions
        tracked_health_func = None
        tracked_weather_func = None
        tracked_video_automation_func = None
        tracked_sse_cleanup_func = None
        tracked_automation_triggers_func = None
        tracked_sync_timelapses_func = None

        if health_check_func:
            tracked_health_func = self._create_tracked_job_wrapper(
                "health_job", health_check_func
            )

        if weather_refresh_func:
            tracked_weather_func = self._create_tracked_job_wrapper(
                "weather_job", weather_refresh_func
            )

        if video_automation_func:
            tracked_video_automation_func = self._create_tracked_job_wrapper(
                "video_automation_job", video_automation_func
            )

        if sse_cleanup_func:
            tracked_sse_cleanup_func = self._create_tracked_job_wrapper(
                "sse_cleanup_job", sse_cleanup_func
            )

        # Always create tracked versions of internal functions
        tracked_automation_triggers_func = self._create_tracked_job_wrapper(
            "automation_triggers_job", self.evaluate_automation_triggers
        )
        tracked_sync_timelapses_func = self._create_tracked_job_wrapper(
            "timelapse_sync_job", self.sync_running_timelapses
        )

        # Inject tracked functions into standard job manager
        self.standard_job_manager.health_check_func = tracked_health_func
        self.standard_job_manager.weather_refresh_func = tracked_weather_func
        self.standard_job_manager.video_automation_func = tracked_video_automation_func
        self.standard_job_manager.automation_triggers_func = (
            tracked_automation_triggers_func
        )
        self.standard_job_manager.sync_timelapses_func = tracked_sync_timelapses_func
        self.standard_job_manager.sse_cleanup_func = tracked_sse_cleanup_func

        jobs_added = self.standard_job_manager.add_all_standard_jobs()

        # Sync all job timings to database after adding standard jobs
        self._update_all_job_timings_in_database()

        return jobs_added

    # Synchronization

    def sync_running_timelapses(self) -> None:
        """Synchronize running timelapses with scheduler jobs and database."""
        try:
            scheduler_logger.debug("Starting timelapse synchronization")

            # Get running and paused timelapses
            active_timelapses = self.timelapse_ops.get_running_and_paused_timelapses()

            # Track which timelapses should have jobs
            expected_jobs = set()
            jobs_added = 0

            for timelapse in active_timelapses:
                timelapse_id = timelapse["id"]
                interval_seconds = timelapse["capture_interval_seconds"]
                job_id = JobIdGenerator.timelapse_capture(timelapse_id)

                expected_jobs.add(job_id)

                # Add job if missing
                if job_id not in self.job_registry:
                    if self.add_timelapse_job(timelapse_id, interval_seconds):
                        jobs_added += 1
                else:
                    # Update next_run_time in database for existing jobs
                    self._sync_job_timing_to_database(job_id)

            # Remove jobs for timelapses that are no longer active
            jobs_removed = 0
            timelapse_jobs = [
                job_id
                for job_id in self.job_registry.keys()
                if job_id.startswith("timelapse_capture_")
            ]

            for job_id in timelapse_jobs:
                if job_id not in expected_jobs:
                    self.remove_job(job_id)
                    jobs_removed += 1

            if jobs_added > 0 or jobs_removed > 0:
                scheduler_logger.info(
                    f"Timelapse sync: +{jobs_added} jobs added, -{jobs_removed} jobs removed"
                )
            else:
                scheduler_logger.debug("Timelapse sync: No changes needed")

        except Exception as e:
            scheduler_logger.error(
                f"Error synchronizing running timelapses: {e}", store_in_db=False
            )

    # Automation Triggers

    def evaluate_automation_triggers(self) -> Dict[str, List[str]]:
        """Evaluate automation triggers for milestone and scheduled videos."""
        return self.automation_evaluator.evaluate_automation_triggers()

    # Immediate Job Scheduling

    async def schedule_immediate_capture(
        self, camera_id: int, timelapse_id: int, priority: str = JobPriority.MEDIUM
    ) -> bool:
        """Schedule immediate capture job."""
        return await self.immediate_job_manager.schedule_immediate_capture(
            camera_id, timelapse_id, priority
        )

    async def schedule_immediate_video_generation(
        self,
        timelapse_id: int,
        video_settings: Optional[Dict[str, Any]] = None,
        priority: str = JobPriority.MEDIUM,
    ) -> bool:
        """Schedule immediate video generation job."""
        return await self.immediate_job_manager.schedule_immediate_video_generation(
            timelapse_id, video_settings, priority
        )

    async def schedule_immediate_overlay_generation(
        self, image_id: int, priority: str = JobPriority.MEDIUM
    ) -> bool:
        """Schedule immediate overlay generation job."""
        return await self.immediate_job_manager.schedule_immediate_overlay_generation(
            image_id, priority
        )

    async def schedule_immediate_thumbnail_generation(
        self, image_id: int, priority: str = JobPriority.MEDIUM
    ) -> bool:
        """Schedule immediate thumbnail generation job."""
        return await self.immediate_job_manager.schedule_immediate_thumbnail_generation(
            image_id, priority
        )

    # Utility Methods

    def get_job_count(self) -> int:
        """Get total number of active jobs."""
        return len(self.job_registry)

    def get_job_info(self) -> Dict[str, Any]:
        """Get information about active jobs."""
        return {
            "total_jobs": len(self.job_registry),
            "job_ids": list(self.job_registry.keys()),
            "scheduler_running": self.scheduler.running,
        }

    def set_timelapse_capture_function(self, func: Callable) -> None:
        """Set the timelapse capture function reference."""
        self.timelapse_capture_func = func
        scheduler_logger.info(
            f"Set timelapse capture function: {func.__name__ if func else 'None'}",
            store_in_db=False,
            emoji=LogEmoji.SUCCESS
        )

        # Update immediate job manager reference
        self.immediate_job_manager.timelapse_capture_func = func

    def get_status(self) -> Dict[str, Any]:
        """
        Get comprehensive scheduler worker status using Service Layer Boundary Pattern.

        Returns:
            Dict[str, Any]: Complete scheduler worker status information
        """
        # Build explicit base status - no super() calls
        base_status = WorkerStatusBuilder.build_base_status(
            name=self.name,
            running=self.running,
            worker_type=WorkerType.SCHEDULER_WORKER.value
        )

        try:
            # Get job information and manager status
            job_info = self.get_job_info()
            manager_status = {
                "immediate_job_manager_healthy": self.immediate_job_manager is not None,
                "standard_job_manager_healthy": self.standard_job_manager is not None,
                "automation_evaluator_healthy": self.automation_evaluator is not None,
            }

            # Use service layer to get typed status object (Service Layer Boundary Pattern)
            scheduler_status = self.scheduler_service.get_worker_status(
                scheduler=self.scheduler,
                job_info=job_info,
                manager_status=manager_status,
                settings_service=self.settings_service,
                scheduling_service=self.scheduling_service,
                capture_timing_enabled=self.timelapse_capture_func is not None,
                automation_enabled=self.automation_evaluator is not None,
            )

            # Add scheduler-specific status information using typed object (follows VideoWorker pattern)
            base_status.update(
                {
                    "worker_type": scheduler_status.worker_type,
                    "scheduler_running": scheduler_status.scheduler_running,
                    "job_registry_size": len(self.job_registry),
                    "settings_service_status": scheduler_status.settings_service_status,
                    "scheduling_service_status": scheduler_status.scheduling_service_status,
                    "capture_timing_enabled": scheduler_status.capture_timing_enabled,
                    "automation_enabled": scheduler_status.automation_enabled,
                    # Job information (clean property access)
                    "total_jobs": (
                        scheduler_status.job_info.total_jobs
                        if scheduler_status.job_info
                        else 0
                    ),
                    "active_jobs": (
                        scheduler_status.job_info.active_jobs
                        if scheduler_status.job_info
                        else 0
                    ),
                    "timelapse_jobs": (
                        scheduler_status.job_info.timelapse_jobs
                        if scheduler_status.job_info
                        else 0
                    ),
                    # Manager status (clean property access)
                    "immediate_job_manager_healthy": (
                        scheduler_status.manager_status.immediate_job_manager_healthy
                        if scheduler_status.manager_status
                        else False
                    ),
                    "standard_job_manager_healthy": (
                        scheduler_status.manager_status.standard_job_manager_healthy
                        if scheduler_status.manager_status
                        else False
                    ),
                    "automation_evaluator_healthy": (
                        scheduler_status.manager_status.automation_evaluator_healthy
                        if scheduler_status.manager_status
                        else False
                    ),
                    # Computed properties from typed model (clean property access)
                    "is_healthy": scheduler_status.is_healthy,
                    "is_functional": scheduler_status.is_functional,
                    "workload_summary": scheduler_status.workload_summary,
                    "has_active_workload": scheduler_status.has_active_workload,
                }
            )

        except Exception as e:
            scheduler_logger.error(f"Error getting scheduler worker status: {e}", store_in_db=False)
            base_status.update(
                {
                    "worker_type": WorkerType.SCHEDULER_WORKER,
                    "scheduler_running": False,
                    "is_healthy": False,
                    "status_error": str(e),
                }
            )

        return base_status

    def get_health(self) -> Dict[str, Any]:
        """
        Get health status for worker management system compatibility.

        This method provides simple binary health information separate
        from the detailed status reporting in get_status().
        """
        return WorkerStatusBuilder.build_simple_health_status(
            running=self.running,
            worker_type=WorkerType.SCHEDULER_WORKER.value,
            additional_checks={
                "scheduler_running": self.scheduler.running if self.scheduler else False,
                "settings_service_available": self.settings_service is not None,
                "scheduling_service_available": self.scheduling_service is not None,
            }
        )
